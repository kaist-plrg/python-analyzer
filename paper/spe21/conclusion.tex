\section{Conclusion}\label{sec:conclusion}
We propose the automated approach to transform TensorFlow DL models written in
Python to models training on multiple GPUs.
We defined four common training patterns for TensorFlow DL models and formal
code transformation rules for each pattern to parallelize training via Horovod
APIs.
Also, we developed a code transformation tool that takes a TensorFlow DL model,
identifies its training pattern via static analysis techniques, and rewrites
it for distributed training by applying transformation rules of the identified
training pattern.
The evaluation showed that our approach is practical in that it transforms 15
out of 16 open-source TensorFlow DL models to the same with their handcrafted
distributed training versions.
We also showed that our approach is effective in that the transformed models
train about 2.28 times faster than the original models.
We believe that our tool reduces model engineers' burdens in rewriting models
in accordance with the documentation of distributed training libraries to
parallelize training.

%Our approach classifies TensorFlow DL models into four common training patterns
%we defined, based on their usage of the TensorFlow APIs.
%Then, our approach rewrites models with Horovod APIs by applying transformation
%rules we formally defined for each training pattern.

%By manually inspecting the Horovod document and code examples,
%we defined \textit{training API patterns} for categorizing TensorFlow
%training codes by their API usage, and constructed \textit{transformation rules}
%to distribute the trainig codes of each tranining patterns.

%We implement the transformation in a form of software,
%which includes class hierarchy analysis and pattern analysis to recognize
%the correct transformation rule for the given input model
%and automatically apply the transformation to produce
%the corresponding distributed model as an output.

%We evaluated the correctness of the transformation tool against
%16 open-source DL models, which all but one transformations are
%successful. 

%Evaluating the training performance of the
%transformed model showed us that none or only minimal amounts of
%hyperparameter tuning is required for distributed training speedup. 

%We believe that our transformation tool frees the users from heavy burden of
%rewriting the model code, and allows them to swiftly move from single-GPU-based
%training to distributed training.

%In future works, we aim to search for methods that can fully automate
%the deployments of DL models on distributed systems, including
%automated hyperparameter tunings suited for the distributed system.
