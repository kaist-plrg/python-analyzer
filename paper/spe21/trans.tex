\section{Code Transformation for Distributed Training}\label{sec:trans}
\subsection{Python Abstract Syntax}\label{sec:pysyn}

We first define the abstract syntax for Python programming language.
The syntax of Python is described in the Python Language Reference \cite{pythonref}.
The reference provides a full grammar specification based on the extended PEG,
and detailed explanation of syntatic components in each section.
We manually examined the grammar and the details
to define the Python abstract sytax.
The syntax is composed of three syntactic components: expressions, statements,
and top-level components.

\begin{tabular}{lrll}
  \nmodule & := & \mul{\nstmt} ~ \ntypignore & \desc{ModuleDef} \\
  \nstmt & ::= & \decolist ~ \kdef ~ \nid ~ \sparen{\nargs} ~ \op{(\krightarrow ~ \nexpr)} ~ \kcolon ~ \optypcomm ~ \mul{\nstmt} & \desc{FunDef} \\ 
  & $|$ & \decolist ~ \kclass ~ \nid ~ \sparen{\mul{\nexpr} \mul{\nkeyword}} ~ \kcolon ~ \mul{\nstmt} & \desc{ClassDef} \\
  & $|$ & \mul{\nexpr} ~ \oassign ~ \nexpr ~ \optypcomm & \desc{Assign} \\
  & $|$ & \optypcomm ~ \kfor ~ \nexpr ~ \kin ~ \nexpr ~ \kcolon ~ \mul{\nstmt} ~ \op{(\kelse ~ \kcolon ~ \mul{\nstmt})}& \desc{ForLoop} \\
  & $|$ & \kwhile ~ \sparen{\nexpr} ~ \kcolon ~ \mul{\nstmt} ~ \op{(\kelse ~ \kcolon ~ \mul{\nstmt})}& \desc{WhileLoop} \\
  & $|$ & \kif ~ \sparen{\nexpr} ~ \kcolon ~ \mul{\nstmt} ~ \op{(\kelse ~ \kcolon ~ \mul{\nstmt})}& \desc{If} \\
  & $|$ & \optypcomm ~ \kwith ~ \mul{\nwithitem} ~ \kcolon ~ \mul{\nstmt} & \desc{With} \\
  & $|$ & \kimport ~ \mul{\nalias} & \desc{Import} \\
  & $|$ & \kfrom ~ \nint ~ \op{\nid} \kimport ~ \mul{\nalias} & \desc{ImportFrom} \\
  & $|$ & \nexpr & \desc{ExprStmt} \\
\end{tabular}

\begin{tabular}{lrll}
  \nexpr & ::= & \nexpr ~ \nboolop ~ \nexpr & \desc{BoolOp} \\
  & $|$ & \nexpr ~ \nbinop ~ \nexpr & \desc{BinaryOp} \\ 
  & $|$ & \nunop ~ \nexpr & \desc{UnaryOp} \\ 
  & $|$ & \lparen{\mul{\nexpr}} & \desc{List} \\ 
  & $|$ & \sparen{\mul{\nexpr}} & \desc{Tuple} \\ 
  & $|$ & \nexpr ~ \mul{(\ncompop ~ \nexpr)} & \desc{CompOp} \\
  & $|$ & \nexpr ~ \sparen{\mul{\nexpr} \mul{\nkeyword}} & \desc{Call} \\
  & $|$ & \nconstant & \desc{Constant} \\
  & $|$ & \nexpr {\tt .}\nid& \desc{Attribute} \\
  & $|$ & \nexpr\lparen{\nexpr} & \desc{Subscript} \\
  & $|$ & \nid & \desc{Name} \\

  \nboolop & ::= & \oand ~ $|$ ~ \oor & \desc{BoolOperator} \\
  \nbinop & ::= & \oand ~ $|$ ~ \osub ~ $|$ ~ \omul & \desc{BinOperator} \\
  \nunop& ::= & \kinvert ~ $|$ ~ \knot ~ $|$ ~ \oadd ~ $|$ ~ \osub & \desc{UnOperator} \\
  \ncompop& ::= & \oeq ~ $|$ ~ \oneq ~ $|$ ~ \olt ~ $|$ ~ \olte ~ $|$ ~ \ogt ~ $|$ ~ \ogte ~ $|$ ~ \ois ~ $|$ ~ \onis ~ $|$ ~ \oin ~ $|$ ~ \onin & \desc{CompOperator}\\
  \nargs & ::= & \mul{(\narg ~ \op{(\oassign ~ \nexpr)})}, ~ \mul{(\narg ~ \op{(\oassign ~ \nexpr)})}, ~ \op{\narg}, ~ \mul{(\narg ~ \op{(\oassign ~ \nexpr)})}, ~ \op{\narg} & \desc{Arguments}\\
  \narg & ::= & \nid ~ \op{\nexpr}~\op{\nstr} & \desc{Argument} \\
  \nkeyword & ::= & \op{\nid} \oassign \nexpr & \desc{Keyword} \\ 
  \nalias & ::= & \nid ~\mul{(.\nid)} \op{(\kas ~ \nid)} & \desc{Alias} \\
  \nwithitem & ::= & \nexpr ~ \op{(\kas ~ \nexpr)} & \desc{WithItem}\\
\end{tabular}

\begin{tabular}{lrll}
  \nconstant & ::= & \knone & \desc{NoneLiteral} \\
  & $|$ & \nint & \desc{IntLiteral} \\
  & $|$ & \nfloat & \desc{FloatLiteral} \\
  & $|$ & \ncomplex & \desc{ComplexLiteral} \\
  & $|$ & \nstr & \desc{StringLiteral} \\
  & $|$ & \nbool & \desc{BooleanLiteral} \\
  & $|$ & \sparen{\mul{\nconstant}} & \desc{TupleLiteral} \\
  & $|$ & {\tt ...} & \desc{Ellipsis} \\
  \ntypignore & ::=  & \mul{\nint} & \desc{TypeIgnore} \\
  \nid & $\in$ & \did \\
  \nstr & $\in$ & \dstr \\
  \nbool & $\in$ & \{{\tt True}, {\tt False}\}\\
  \nint & $\in$ & $\mathbb{Z}$ \\
  \nfloat & $\in$ & $\mathbb{R}$ \\
  \ncomplex & $\in$ & $\mathbb{C}$ \\
\end{tabular}

Expressions are parts of the code that evaluates to a value.
Python has 5 kinds of primitive values, 
which are numbers, strings, booleans, the value {\itshape None} and {\itshape Ellipsis}.
The value None is used to denote a undefined value,
similar to the value {\itshape null} in Java.
The value Ellipsis corresponds to the notation ``...",
which can be used as an special placeholder meaning expansion of the sequence. 
Python has composite types of tuple, list, set, map, and custom classes.
The expression syntax defines ways to build up values
and complex expressions such as operators, comprehension, and function calls. 

Statements are parts of the code that changes the program state,
such as variable binding or control flow. 
Python statements are categorized into 
simple statements which denote a single state changing step, 
or compound statements which are composed of multiple statements.

Simple statements include assignment statements and import statements.
Assignment statements are used to declare a new variable and its value
or update a variable value.
Import statements are used to specify a module, load it
and get definitions of the module into current namespace.
In import statements, each target module and its aliased name is represented
as alias.   
Note that procedure call is a special case of expression statements,
where the expression is a function call.

Compound statements include conditional statements, loop statements,
and definitions for functions and classes.
Additionally, the with statement is an special kind of compound statement.
With statement is identical to the assignment statement 
in a way that it binds an expression to a name, 
but the statement additionally adds implicit calls
to the object's methods related to initialization and destruction.
Similar to the alias in import statement,
with statements use WithItem to represent then ame and expression.

Top-level components are representation of the program
in different execution environment of the Python interpreter.
For example, a module represents a Python code file, composed of
multiple definitions speicified of statements. 
The full Python abstract syntax is attched in the supplementary material.

\subsection{Training API Patterns for TensorFlow ML model}

Before we define transformation rules for TensorFlow models,
we categorize the model training codes by their API usage pattern.
TensorFlow library provides various methods for training process.


\lstinputlisting[language=Python, caption=Training API usage example]
{pattern_ex.py}

The above figure illustrates two different API usage for model training.
Line 7 to 16 uses low-level APIs to manually compute the training loss.
In line 10, the tf.GradientTape object is instantiated by `with' statement.
Inside the `with' statement, a prediction loss is computed against
a given training data.
The GradientTape object records the computaions occur inside the scope
and later the gradient can be computed with `gradient()' method call.
Then the model parameters are optimized against the gradient
by the method `apply\_gradients'.
The training step is manually repeated by `for' loop in line 8,
where each training data is taken from the `tf.data.Dataset` instance.

Line 18 to 20 uses high-level APIs of `tf.keras.Model' class for training.
The `compile' method in line 19 assigns the optimizer and loss
function to the training configuration.
The `fit' method then invokes the training process in one line.
The method automatically feed the training data to the model,
compute the loss, and apply the gradients to model parameters.

While both code fragments trains the model in a same way, 
the code structures significantly differ.
Using high-level APIs simplifies the program,
reducing additional codes that compute the prediction loss and apply gradients.
Low-level APIs are verbose, however, developer can fully control
the training process.

Different training APIs require different transformation rules.


\subsection{Transformation Rule for Distributed TensorFlow ML model}

% breifly introduce the transform function concept

In this section, we describe the transformation rule that
transforms single-GPU based TensorFlow model codes into
multi-GPU based TensorFlow model codes.
We informally understand code transformation rule as
conditions to select the target code parts
and methods to actually transform them into another.
The methods include addition, modification, and deletion of
specific code parts.
Currently, code transformation for distributed ML training
is only described by set of examples and informal explanations.
In order to automate the code transformation process,
we need to formally define the code transformation rule
and ways to convert the definition into software implementation.
We propose a formal definition of code transformation rule
for distributed ML training, and implement the automatic code transformation
software based on the formal definition.

Code transformation is formally defined as a pure function from AST to AST.
We call this function a transform function.
We may define multiple transform functions that act on different
language constructs and use them to define other transform functions.
For example, in order to transform a Python code into another,
we define a transform function that takes Module AST and returns Module AST.
Inside the Module transform function definition,
we may use Statement transform function to transform statements
that compose the Module AST.

Together with the AST parameter, transform functions take and return
the environment parameter.
Environment parameters are used to store specific identifiers
and pass it to the other calls of the transform function.
For example, statement transform function frequently use 
the identifier bound to the TensorFlow module.
The module name first appears from the import statement.
The transform function call on the import statement stores
the TensorFlow module name on the environment and returns it.
Then the later function calls to other statements can
retrieve the TensorFlow module name from the environment parameter.

% explain transform function with example

\begin{lstlisting}[language=Python, caption = Original code example]
import tensorflow as tf
optimizer = tf.keras.optimizers.Adam(lr)\end{lstlisting}

\begin{lstlisting}[language=Python, caption = Transformed code example]
import tensorflow as tf
# import and init horovod module
import horovod.tensorflow as hvd
hvd_broadcast_done = False
hvd.init()
import tensorflow.keras as keras

# scale the learning rate
optimizer = tf.keras.optimizers.Adam(lr * hvd.size())
# wrap the optimizer object
optimizer = hvd.DistributedOptimizer(optimizer)
\end{lstlisting}

We first describe how the transform function works by example.
The above figures illustrate a pair of TensorFlow model codes
before and after the transformation.
Informally, three kinds of transformation occur in between;
1) import and initialize the horovod module;
2) scale the optimizer's learning rate by {\tt hvd.size()};
3) Wrap the optimzier with {\tt hvd.DistributedOptimizer}.

The original code parses into a module AST with a list of 2 statements,
an import statement and an assign statement.

\begin{lstlisting}[language=Scala]
Module(List(
  ImportStmt(Id('tensorflow'), Id('tf')),
  AssignStmt(
    Id('optimizer'), 
    CallExpr(
      Expr('tf.keras.optimizers.Adam'),
      Args(Id('lr'))
    )
  )
))
\end{lstlisting}

\begin{tabular}{lcl}
  \tmodule{[\nstmtsubs{1}, \nstmtsubs{2}] ~ \ntypignore} 
  & \kteq & \tsstmt{[\nstmtsubs{1}, \nstmtsubs{2}]}{\smodenvempty} \\

  & \kteq & \ktlet ~ \mul{\nstmtsubs{1}}$'$, \smodenvsubs{1} ~ \kteq ~ 
  \tstmt{\nstmtsubs{1}}{\smodenvempty} ~ \ktin \\

  & & \ktlet ~ \mul{\nstmtsubs{2}}$'$, \smodenvsubs{2} ~ \kteq ~ 
  \tstmt{\nstmtsubs{2}}{\smodenvsubs{1}} ~ \ktin \\

  & & (\mul{\nstmtsubs{1}}$'$ \ktconl ~ \mul{\nstmtsubs{2}}$'$) \\ 
\end{tabular}

The figure describes how the module transform function 
is evaluated on the example module AST.
The module transform function, $\fkmodule$
applies statement list transform function $\fksstmt$ to its statement list.
Then $\fksstmt$ applies the statement transform funciton $\fkstmt$
to each statement in the list.
In addition, $\fksstmt$ passes the environment parameter $\sigma$
from a $\fkstmt$ call to the next $\fkstmt$ call.

\begin{tabular}{rcll}
  \tstmt{\nstmtsubs{1}}{\smodenvempty} & \kteq & 
  \tstmt{{\tt import tensorflow as tf}}{\smodenvempty} & \\

  & \kteq & \tstmt{\kimport ~ \mul{\nalias}}{\smodenvempty} & 
  (a) Pattern matching the input \\

  & & {\tt matching} ~ ( & \\
  && \indent \kimport ~ \mul{\nalias} \kteq ~ 
  \kimport ~ [{\tt tensorflow} \kas ~ {\tt tf}], & \\
  && \indent \mul{\nalias} \kteq ~ [\naliassubs{1}], & \\ 
  && \indent \naliassubs{1} \kteq ~ {\tt tensorflow} \kas ~ {\tt tf} ~ ) & \\

  & \kteq & 
  \ktlet ~ \smodenvsubs{1} ~ \kteq ~ \taalias{[\naliassubs{1}]}{\smodenv} 
  \ktin & 
  (b) Check if the TensorFlow module imported \\
  && \ktif ~ \smodenvsubs{1} ~ \envsub ~ \smodenv ~ 
  \kteq ~ [\tflow $\mapsto$ \nid] ~ \ktthen &\\ 
  && ([\kimport ~ \naliassubs{1}, & \\
  && {\tt import horovod.tensorflow as hvd}, & \\
  && {\tt hvd\_broadcast\_done = False}, & \\
  && {\tt hvd.init()}], \smodenvsubs{1}) & \\
  
  & \kteq &
  ([\kimport ~ {\tt tensorflow} \kas ~ {\tt tf}, & 
  (c) Construct output statements \\
  && {\tt import horovod.tensorflow as hvd}, & \\
  && {\tt hvd\_broadcast\_done = False}, & \\
  && {\tt hvd.init()}], \smodenvsubs{1}) & \\

  \kwith ~ \smodenvsubs{1} 
  & \kteq & \talias{\naliassubs{1}}{\smodenvempty} & \\
  & = & \talias{{\tt tensorflow} \kas ~ {\tt tf}}{\smodenvempty} & \\ 
  & \kteq & \smodenvempty[\tflow $\mapsto$ {\tt tf}] & \\
  & \kteq & [\tflow $\mapsto$ {\tt tf}] & \\
\end{tabular}

The first $\fkstmt$ call receives the statement
{\tt import tensorflow as tf} as an input.
In part (a), the function first matches the input statement
with the pattern $\kimport ~ \mul{\nalias}$.
Transform functions use pattern matching to discriminate target ASTs
by their syntactic structure.
Part (b) specifies the pattern guard, which describes detailed condition
on the content of the input.
The pattern guard checks if the import statement
is importing the TensorFlow module.
In process, the alias transform function $\fkalias$ is applied on the
{\tt tensorflow as tf}.
Note that $\fkalias$ also stores the module name {\tt tf}
in the environment parameter as a form of mapping;
later calls on transform function can retreive the
TensorFlow module name from the returned environment, $\smodenvsubs{1}$.
Finally, the part (c) constructs the output statements
and returns it with $\smodenvsubs{1}$.

% TODO typesetting this!!!!!
\begin{tabular}{rcll}
  \tstmt{\nstmtsubs{2}}{\smodenvempty} & \kteq &
  \tstmt{{\tt optimizer = tf.keras.optimizers.Adam(lr)}}{\smodenvsubs{1}} &\\
  &\kteq&
  \tstmt{\nidsubs{r} \oassign 
  \nexprsubs{1} \sparen{\nexprsubs{11} ... \nexprsubs{1n} ~ 
  \op{(\nidsubs{1} \oassign)} \nexprsubs{21} ... 
  \op{(\nidsubs{k} \oassign)} \nexprsubs{2k}}}{\smodenvsubs{1}} &\\
  && {\tt matching} ~ ( 
  \indent\indent\indent\indent\indent (a) Pattern matching the input &\\
  && \indent \nidsubs{r} \kteq ~ {\tt optimizer}, &\\
  && \indent \nexprsubs{1} = {\tt tf.keras.optimizers.Adam}, &\\
  && \indent \nexprsubs{11}= {\tt lr}~) &\\

  &\kteq& \ktif ~ \smodenvsubs{1}(\tflow) ~ \kteq ~ \nidsubs{t} ~ 
  \indent\indent\indent\indent\indent
  (b) Check if it calls {\tt tf.keras.optimizers.Adam} &\\ 
  && \ktand ~ 
  \nexprsubs{1} ~ \kteq ~ {\tt \nidsubs{t}.keras.optimizers.Adam} ~ 
  \ktthen& \\

  && ([\nidsubs{r} \oassign \nexprsubs{1} 
  \sparen{\nexprsubs{11} {\tt * hvd.size()} ~ ... ~ \nexprsubs{1n} 
  ~\op{(\nidsubs{1} \oassign)} \nexprsubs{21} ... 
  \op{(\nidsubs{k} \oassign)} \nexprsubs{2k}}], &\\
  && \smodenvsubs{1}[\optmizer $\mapsto$ \nidsubs{r}])&\\
  
  &\kteq& 
  ([{\tt optimizer = tf.keras.optimizers.Adam(lr * hvd.size())}], &\\   
  && \smodenvsubs{1}[\optmizer $\mapsto$ \nidsubs{r}])
  \indent\indent\indent\indent\indent
  (c) Construct output statements &\\ 
\end{tabular}

The second $\fkstmt$ receives the statement
{\tt optimizer = tf.keras.optimizers.Adam(lr)} as an input.
The part (a) pattern matches the input to the assign statement pattern
with right-hand side of function call expression.
The part (b) is a pattern guard that checks if
the function call is {\tt tf.keras.optimizers.Adam}.
Note that the guard refers to the environment parameter
to check the TensorFlow module identifier.
Because after the first $\fkstmt$ call,
the environment parameter stores the TensorFlow module identifier {\tt tf},
so the second $\fkstmt$ call can use the information to
check if the function call is indeed a constructor for TensorFlow
optimizer object.
In the part (c), the output statement is returned.
As specified in the transform function definition, 
the first argument expression is multiplied by {\tt hvd.size()}.

\begin{tabular}{rcll}
  \tmodule{[\nstmtsubs{1}, \nstmtsubs{2}] ~ \ntypignore} 
  &\kteq& (\mul{\nstmtsubs{1}}$'$ \ktconl ~ \mul{\nstmtsubs{2}}$'$) &\\ 
  &\kteq& 
  [\kimport ~ {\tt tensorflow} \kas ~ {\tt tf}, &\\ 
  && {\tt import horovod.tensorflow as hvd}, & \\
  && {\tt hvd\_broadcast\_done = False}, & \\
  && {\tt hvd.init()}, &\\
  && {\tt optimizer = tf.keras.optimizers.Adam(lr * hvd.size())}] &\\   
\end{tabular}

Finally, the output statement lists are concatenated as specified in the
$\fksstmt$, and the transformed module AST is constructed.


The above figure illustrates the example of a statement transformation.
Intutitive understanding of the transformation is as follows:
if the input code is assignment statment 
that assigns a new `tf.keras.optimizer.Adam' instance,
then multiply `hvd.size()' on learning rate argument expression of the
instance constructor function.
The transform function should describe two aspects of the sentence;
first it should describe the condition of "assignment statement that
creates `tf.keras.optimizer.Adam' instance";
second it should describe the transformation sentence
of "multiply `hvd.size()' on the learning rate argument". 

(TODO figure of part of transform function describing the example) 

The figure defines the part of Statement transform function. 
The pattern matched by the function is described on the first line;
it matches the assignment statements with operator `=' and
right-hand side of function call expression.
Note that the input AST components are matched onto pattern variables.
This allows the definition to reuse the input AST component
when constructing the output AST.
The second line illustrates pattern guard that matches the input AST content.
It checks the callee expression is the expression `tf.keras.optimizers.Adam'.
The pattern guard uses the environment parameter $\sigma$ to retrieve
module name for the Keras module.

The figure defines the following part of the function.
It describes the construction of an output AST and environment.
The output AST is assignment statement which
the right-hand side function argument expression is modified.
As previously mentioned, the construction use pattern matched variables
to reuse the input AST components.
The difference is that first argument expression is multiplied by `hvd.size()',
which formally describes the transformation sentence.

We describe the transform function definition.
\begin{itemize}
  \item explain types and aux functions
  \item explain trans Module/Stmt list (env passing \& concating the results
  \item explain trans Stmt (pattern match \& pattern guard)
  \item explain trans Expr (recursively check all expr in code)
  \item explain trans Alias \& WithItem (stores id on env)
\end{itemize}

We inspected multiple references to define the whole transform function.
Horovod documentation\cite{horovodtf} describes the code modification
required to change trainig script. It describes six steps to modify
existing training scripts to distributed training scripts. 
In addition to 

