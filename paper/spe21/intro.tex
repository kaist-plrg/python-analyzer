\section{Introduction}\label{sec:intro}
\begin{itemize}
  \item ML is widely used in various domains these days.
  \item Distributed Training can reduce the training time.
  \item To train ML model on multi-GPUs, code transformation is required but it
    also requires human efforts. The code transformation is simple but only
    some examples describe the transformation.
  \item In this paper, we propose an automated Python code transformation that
    enables TensorFlow ML models to run on multi-GPUs (formal rule of the code
    transformation \& automated code transformation tool).
  \item Describe contributions of this paper.
\end{itemize}

(Main topic sentences for each paragraphs)

Recent advancements in machine learning(ML) opened wide possibility of
applying artificial intelligence in various fields.

While the performance of ML models continue to improve,
their growing training time is bottleneck in the development process.
This is due to the increase of the size of the model parameters 
and training datasets.

Distributed training can reduce the training time 
by parallelizing computation workloads among a number of processors. 

For easier use, distributed training libraries are commonly used.
As an example, Horovod is a Python library for distributed training that
supports various DL frameworks such as PyTorch, TensorFlow, and Keras. 

Transforming DL model for distributed training involves
manual code transformation. This requires intensive labor and time costs.

To solve this problem, we utilize code transformation to automate the process.

In this paper, we propose an automated Python code transformation that enables
TensorFlow ML models to perform distributed training.

